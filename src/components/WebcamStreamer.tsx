// // WebcamStreamer.tsx
// import React, { useEffect, useRef } from 'react';

// interface Props {
//     isRecording: boolean;
//     onTranscriptUpdate?: (text: string) => void;
//     onExpressionUpdate?: (emotion: string) => void;
//     onFeedbackUpdate?: (feedback: any) => void;
// }

// const WebcamStreamer: React.FC<Props> = ({ isRecording, onTranscriptUpdate, onExpressionUpdate, onFeedbackUpdate }) => {
//     const videoRef = useRef<HTMLVideoElement>(null);
//     const mediaRecorderRef = useRef<MediaRecorder | null>(null);
//     const streamRef = useRef<MediaStream | null>(null);
//     const chunksRef = useRef<Blob[]>([]);
//     const transcriptSocketRef = useRef<WebSocket | null>(null);
//     const expressionSocketRef = useRef<WebSocket | null>(null);

//     useEffect(() => {
//         const initStream = async () => {
//             const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
//             streamRef.current = stream;

//             if (videoRef.current) {
//                 videoRef.current.srcObject = stream;
//                 videoRef.current.onloadedmetadata = () => {
//                     videoRef.current?.play().catch((err) => {
//                         console.error("ðŸŽ¥ ìž¬ìƒ ì˜¤ë¥˜:", err);
//                     });
//                 };
//             }
//         };

//         initStream();

//         return () => {
//             streamRef.current?.getTracks().forEach(track => track.stop());
//         };
//     }, []);

//     useEffect(() => {
//         if (isRecording && streamRef.current) {
//             chunksRef.current = [];

//             transcriptSocketRef.current = new WebSocket('ws://localhost:8000/ws/transcript');
//             expressionSocketRef.current = new WebSocket('ws://localhost:8000/ws/expression');

//             const mimeType = MediaRecorder.isTypeSupported('video/webm;codecs=vp8,opus')
//                 ? 'video/webm;codecs=vp8,opus'
//                 : '';

//             const recorder = new MediaRecorder(streamRef.current, mimeType ? { mimeType } : {});
//             mediaRecorderRef.current = recorder;

//             recorder.ondataavailable = (event) => {
//                 if (event.data.size > 0) {
//                     chunksRef.current.push(event.data);
//                 }
//             };

//             recorder.onstop = async () => {
//                 const blob = new Blob(chunksRef.current, { type: recorder.mimeType });
//                 const arrayBuffer = await blob.arrayBuffer();

//                 // ìŒì„± ë°ì´í„° ì „ì†¡ (STT)
//                 if (transcriptSocketRef.current?.readyState === WebSocket.OPEN) {
//                     transcriptSocketRef.current.send(arrayBuffer);
//                 }

//                 // í‘œì • ë°ì´í„° ì „ì†¡ (ì˜ìƒ ë™ì¼ ì „ì†¡)
//                 if (expressionSocketRef.current?.readyState === WebSocket.OPEN) {
//                     expressionSocketRef.current.send(arrayBuffer);
//                 }

//                 chunksRef.current = [];
//             };

//             recorder.start();
//         }

//         if (!isRecording && mediaRecorderRef.current) {
//             mediaRecorderRef.current.stop();

//             // STT ê²°ê³¼ ìˆ˜ì‹ 
//             if (transcriptSocketRef.current) {
//                 transcriptSocketRef.current.onmessage = (event) => {
//                     const data = JSON.parse(event.data);
//                     onTranscriptUpdate?.(data.transcript);
//                     onFeedbackUpdate?.(data.feedback);
//                 };

//                 transcriptSocketRef.current.onclose = () => {
//                     console.log("ðŸ›‘ Transcript WebSocket ì¢…ë£Œ");
//                 };
//             }

//             // í‘œì • ê²°ê³¼ ìˆ˜ì‹ 
//             if (expressionSocketRef.current) {
//                 expressionSocketRef.current.onmessage = (event) => {
//                     const data = JSON.parse(event.data);
//                     onExpressionUpdate?.(data.expression);
//                 };

//                 expressionSocketRef.current.onclose = () => {
//                     console.log("ðŸ›‘ Expression WebSocket ì¢…ë£Œ");
//                 };
//             }

//         }

//     }, [isRecording]);

//     return <video ref={videoRef} width={600} muted autoPlay />;
// };

// export default WebcamStreamer;

import React, { useEffect, useRef } from 'react';

interface Props {
    isRecording: boolean;
    onTranscriptUpdate?: (text: string) => void;
    onExpressionUpdate?: (expression: string) => void;
    onFeedbackUpdate?: (feedback: any) => void;
}

const WebcamStreamer: React.FC<Props> = ({
    isRecording,
    onTranscriptUpdate,
    onExpressionUpdate,
    onFeedbackUpdate
}) => {
    const videoRef = useRef<HTMLVideoElement>(null);
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const streamRef = useRef<MediaStream | null>(null);
    const chunksRef = useRef<Blob[]>([]);

    const transcriptSocketRef = useRef<WebSocket | null>(null);
    const expressionSocketRef = useRef<WebSocket | null>(null);
    const expressionIntervalRef = useRef<NodeJS.Timeout | null>(null);

    // ðŸŽ¥ ì›¹ìº  ì´ˆê¸°í™”
    useEffect(() => {
        const initStream = async () => {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
            streamRef.current = stream;

            if (videoRef.current) {
                videoRef.current.srcObject = stream;
                videoRef.current.onloadedmetadata = () => {
                    videoRef.current?.play().catch((err) => {
                        console.error("ðŸŽ¥ ìž¬ìƒ ì˜¤ë¥˜:", err);
                    });
                };
            }
        };

        initStream();

        return () => {
            streamRef.current?.getTracks().forEach((track) => track.stop());
        };
    }, []);

    // ðŸŽ™ï¸ ë…¹í™” ë° WebSocket ê´€ë¦¬
    useEffect(() => {
        if (isRecording && streamRef.current) {
            chunksRef.current = [];

            // WebSocket ì—°ê²°
            transcriptSocketRef.current = new WebSocket('ws://localhost:8000/ws/transcript');
            expressionSocketRef.current = new WebSocket('ws://localhost:8000/ws/expression');

            // âœ… expression ìˆ˜ì‹  í•¸ë“¤ëŸ¬ ë“±ë¡
            expressionSocketRef.current.onmessage = (event) => {
                const data = JSON.parse(event.data);
                console.log("ðŸ“¸ ì‹¤ì‹œê°„ expression ìˆ˜ì‹ :", data);
                onExpressionUpdate?.(data.expression);
            };
            expressionSocketRef.current.onopen = () => {
                console.log("ðŸŸ¢ Expression WebSocket ì—°ê²° ì„±ê³µ");
            };

            const mimeType = MediaRecorder.isTypeSupported('video/webm;codecs=vp8,opus')
                ? 'video/webm;codecs=vp8,opus'
                : '';

            const recorder = new MediaRecorder(streamRef.current, mimeType ? { mimeType } : {});
            mediaRecorderRef.current = recorder;

            // ìŒì„± ë…¹í™” ë°ì´í„° ìˆ˜ì§‘
            recorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    chunksRef.current.push(event.data);
                }
            };

            // â¹ï¸ ë…¹í™” ì¢…ë£Œ ì‹œ STT ë°ì´í„° ì „ì†¡
            recorder.onstop = async () => {
                const blob = new Blob(chunksRef.current, { type: recorder.mimeType });
                const arrayBuffer = await blob.arrayBuffer();

                if (transcriptSocketRef.current?.readyState === WebSocket.OPEN) {
                    transcriptSocketRef.current.send(arrayBuffer);
                }

                chunksRef.current = [];
            };

            recorder.start();

            // ðŸ§â€â™‚ï¸ í”„ë ˆìž„ì„ 0.5ì´ˆë§ˆë‹¤ ì „ì†¡
            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext("2d");
            canvas.width = 640;
            canvas.height = 480;

            expressionIntervalRef.current = setInterval(() => {
                if (
                    videoRef.current &&
                    ctx &&
                    expressionSocketRef.current?.readyState === WebSocket.OPEN
                ) {
                    ctx.drawImage(videoRef.current, 0, 0, canvas.width, canvas.height);
                    canvas.toBlob((blob) => {
                        if (blob) {
                            blob.arrayBuffer().then((buffer) => {
                                expressionSocketRef.current!.send(buffer);
                            });
                        }
                    }, "image/jpeg");
                }
            }, 500);
        }

        // â¹ï¸ ë…¹í™” ì¤‘ì§€
        if (!isRecording && mediaRecorderRef.current) {
            mediaRecorderRef.current.stop();

            if (transcriptSocketRef.current) {
                transcriptSocketRef.current.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    console.log("ðŸ“ STT ìˆ˜ì‹ :", data);
                    onTranscriptUpdate?.(data.transcript);
                    onFeedbackUpdate?.(data.feedback);
                };
                transcriptSocketRef.current.onclose = () => {
                    console.log("ðŸ›‘ Transcript WebSocket ì¢…ë£Œ");
                };
            }

            if (expressionSocketRef.current) {
                expressionSocketRef.current.onclose = () => {
                    console.log("ðŸ›‘ Expression WebSocket ì¢…ë£Œ");
                };
            }

            if (expressionIntervalRef.current) {
                clearInterval(expressionIntervalRef.current);
            }
        }

        return () => {
            if (expressionIntervalRef.current) {
                clearInterval(expressionIntervalRef.current);
            }
        };
    }, [isRecording]);

    return <video ref={videoRef} width={640} height={480} muted autoPlay />;
};

export default WebcamStreamer;
